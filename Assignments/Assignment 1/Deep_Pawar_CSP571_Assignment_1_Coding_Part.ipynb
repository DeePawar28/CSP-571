{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Deep Pawar (A20545137)\n",
        "\n",
        "Professor: Oleksandr Narykov\n",
        "\n",
        "Institute: Illinois Institute of Technology\n",
        "\n",
        "CSP 571: Data Preparation and Analysis\n",
        "\n",
        "Fall 2024 - Assignment 1"
      ],
      "metadata": {
        "id": "AE_wBtaQBEqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. 1. Download ‘Automobile’ dataset from the UCI ML repository\n",
        "      (https://archive.ics.uci.edu/dataset/10/automobile)\n",
        "\n",
        "Q. 2. Create pandas dataset with the following columns:\n",
        "\n",
        " ![dpa.png](data:image/png;base64,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)\n",
        "\n",
        "Q. 3. (5 point) Designate the first 60% of data as a training set, the next 20% as a validation set, and the last 20% as a test set. You can keep column Y as a part of dataset or separate it into a stand-alone vector."
      ],
      "metadata": {
        "id": "LmgQativCAfY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Vm3a8eY2f7hd"
      },
      "outputs": [],
      "source": [
        "#Importing the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "\n",
        "#Loading dataset into the variable named 'df'\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
        "columns = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', 'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
        "\n",
        "df = pd.read_csv(url, names=columns, na_values='?')\n",
        "\n",
        "#Creating the dataset with the given features and target columns\n",
        "X = df[['wheel-base', 'compression-ratio', 'engine-size', 'length', 'width']]\n",
        "Y = df['city-mpg']\n",
        "\n",
        "#Split data into training set as 60%, validation set as 20%, and test set as 20%\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. 4. (10 point) Consider three linear models for the regression problem – linear regression, ridge regression, and LASSO. Fit them with default parameters on the training set and estimate performance on both validation and test sets. Use MSE, Pearson Correlation Coefficient (PCC), and Coefficient of determination (R2) metrics."
      ],
      "metadata": {
        "id": "Orj9WfzuHV91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Linear Regression, Ridge Regression and Lasso Regression Models\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge Regression\": Ridge(),\n",
        "    \"Lasso Regression\": Lasso()\n",
        "}\n",
        "\n",
        "#Creating a evaluation function to compute MSE, PCC, and R²\n",
        "def model_evaluation(model, X, Y, set_name):\n",
        "    predictions = model.predict(X)\n",
        "    mse = mean_squared_error(Y, predictions)\n",
        "    pcc, _ = pearsonr(Y, predictions)\n",
        "    r2 = r2_score(Y, predictions)\n",
        "\n",
        "    print(f\"\\nThe Performance on {set_name} set : \")\n",
        "    print(f\"Value of MSE : {mse}\")\n",
        "    print(f\"Value of PCC : {pcc}\")\n",
        "    print(f\"Value of R²  : {r2}\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n ----------- {name} ------------\")\n",
        "\n",
        "    #Fitting the model on training set\n",
        "    model.fit(X_train, Y_train)\n",
        "    #Performing Evaluation on validation set\n",
        "    model_evaluation(model, X_val, Y_val, \"Validation\")\n",
        "    #Performing Evaluation on test set\n",
        "    model_evaluation(model, X_test, Y_test, \"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqOCYcQpgkHP",
        "outputId": "360af04b-c6de-41b1-e2d6-6e90233248a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ----------- Linear Regression ------------\n",
            "\n",
            "The Performance on Validation set : \n",
            "Value of MSE : 20.295140049988714\n",
            "Value of PCC : 0.8227098068087262\n",
            "Value of R²  : 0.665796806253492\n",
            "\n",
            "The Performance on Test set : \n",
            "Value of MSE : 10.539190179156172\n",
            "Value of PCC : 0.8760184188938203\n",
            "Value of R²  : 0.7297272510883063\n",
            "\n",
            " ----------- Ridge Regression ------------\n",
            "\n",
            "The Performance on Validation set : \n",
            "Value of MSE : 20.305135742307048\n",
            "Value of PCC : 0.8226083400357305\n",
            "Value of R²  : 0.6656322056501818\n",
            "\n",
            "The Performance on Test set : \n",
            "Value of MSE : 10.544284340318582\n",
            "Value of PCC : 0.8759572745966\n",
            "Value of R²  : 0.7295966136372916\n",
            "\n",
            " ----------- Lasso Regression ------------\n",
            "\n",
            "The Performance on Validation set : \n",
            "Value of MSE : 23.00353047878484\n",
            "Value of PCC : 0.7949368131887922\n",
            "Value of R²  : 0.6211973243584833\n",
            "\n",
            "The Performance on Test set : \n",
            "Value of MSE : 11.494502175984902\n",
            "Value of PCC : 0.8667530890574934\n",
            "Value of R²  : 0.7052287084999143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5. (20 point) For ridge regression and LASSO investigate the following values of parameter alpha (multiplication coefficient for regularization) on the validation set and its effect on model performance: [0., 0.25, 0.5, 1., 1000.].\n",
        "\n",
        "Which value gives the best performance on the validation set? Retrain the model with this value and calculate the same metrics on the test set."
      ],
      "metadata": {
        "id": "wzNnfTw9LU6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Given Range of alpha values (where alpha will be 0 for Ridge and Lasso)\n",
        "alphas = [0., 0.25, 0.5, 1., 1000.]\n",
        "\n",
        "#Creating a Evaluation function to compute MSE, PCC, and R²\n",
        "def model_evaluation(model, X, Y, set_name):\n",
        "    predictions = model.predict(X)\n",
        "    mse = mean_squared_error(Y, predictions)\n",
        "    if np.std(predictions) == 0 or np.std(Y) == 0:\n",
        "        pcc = 0\n",
        "    else:\n",
        "        pcc, _ = pearsonr(Y, predictions)\n",
        "    r2 = r2_score(Y, predictions)\n",
        "    return mse, pcc, r2\n",
        "\n",
        "#Creating a Function to find best alpha on validation set\n",
        "def finding_best_alpha(ModelClass, X_train, Y_train, X_val, Y_val, alphas, model_name):\n",
        "    best_alpha = None\n",
        "    best_mse = float('inf')\n",
        "    for alpha in alphas:\n",
        "        if alpha == 0:\n",
        "            model = LinearRegression()\n",
        "        else:\n",
        "            model = ModelClass(alpha=alpha)\n",
        "\n",
        "        model.fit(X_train, Y_train)\n",
        "        mse, pcc, r2 = model_evaluation(model, X_val, Y_val, \"Validation\")\n",
        "        print(f\"\\n-----------The {model_name} with alpha = {alpha}-----------------\\n\")\n",
        "        print(f\"MSE : {mse}, \\nPCC : {pcc}, \\nR²  : {r2}\")\n",
        "\n",
        "        #If loop to Track best alpha based on MSE\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_alpha = alpha\n",
        "    return best_alpha, best_mse\n",
        "\n",
        "#Finding the best alpha for Ridge\n",
        "best_alpha_ridge, _ = finding_best_alpha(Ridge, X_train, Y_train, X_val, Y_val, alphas, \"Ridge Regression\")\n",
        "\n",
        "#Finding the best alpha for Lasso\n",
        "best_alpha_lasso, _ = finding_best_alpha(Lasso, X_train, Y_train, X_val, Y_val, alphas, \"Lasso Regression\")\n",
        "\n",
        "#Retraining with best alpha to perform evaluation on the test set\n",
        "print(f\"\\n-------------------------------------------------------------------\")\n",
        "print(f\"\\nThe value of Best alpha for Ridge : {best_alpha_ridge}\")\n",
        "print(f\"The value of Best alpha for Lasso : {best_alpha_lasso}\")\n",
        "print(f\"\\n-------------------------------------------------------------------\")\n",
        "#Retraining Ridge with best alpha to perform evaluation on the test set\n",
        "if best_alpha_ridge == 0:\n",
        "    ridge_best_model = LinearRegression()\n",
        "\n",
        "else:\n",
        "    ridge_best_model = Ridge(alpha=best_alpha_ridge)\n",
        "\n",
        "ridge_best_model.fit(X_train, Y_train)\n",
        "print(\"\\nEvaluating Ridge on Test Set:\")\n",
        "\n",
        "mse, pcc, r2 = model_evaluation(ridge_best_model, X_test, Y_test, \"Test\")\n",
        "print(f\"MSE : {mse}, \\nPCC : {pcc}, \\nR²  : {r2}\")\n",
        "\n",
        "#Retraining Lasso with the best alpha to perform evaluation on the test set\n",
        "if best_alpha_lasso == 0:\n",
        "    lasso_best_model = LinearRegression()\n",
        "\n",
        "else:\n",
        "    lasso_best_model = Lasso(alpha=best_alpha_lasso)\n",
        "\n",
        "lasso_best_model.fit(X_train, Y_train)\n",
        "print(\"\\nEvaluating Lasso on Test Set:\")\n",
        "\n",
        "mse, pcc, r2 = model_evaluation(lasso_best_model, X_test, Y_test, \"Test\")\n",
        "print(f\"MSE : {mse}, \\nPCC: {pcc}, \\nR²: {r2}\")\n",
        "print(f\"\\n-------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZM5RZaZgrce",
        "outputId": "6f673af9-4e42-4b35-a277-02e788094572"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----------The Ridge Regression with alpha = 0.0-----------------\n",
            "\n",
            "MSE : 20.295140049988714, \n",
            "PCC : 0.8227098068087262, \n",
            "R²  : 0.665796806253492\n",
            "\n",
            "-----------The Ridge Regression with alpha = 0.25-----------------\n",
            "\n",
            "MSE : 20.29764385182555, \n",
            "PCC : 0.822684373514665, \n",
            "R²  : 0.6657555757634182\n",
            "\n",
            "-----------The Ridge Regression with alpha = 0.5-----------------\n",
            "\n",
            "MSE : 20.30014439396188, \n",
            "PCC : 0.8226589847299334, \n",
            "R²  : 0.6657143989513341\n",
            "\n",
            "-----------The Ridge Regression with alpha = 1.0-----------------\n",
            "\n",
            "MSE : 20.305135742307048, \n",
            "PCC : 0.8226083400357305, \n",
            "R²  : 0.6656322056501818\n",
            "\n",
            "-----------The Ridge Regression with alpha = 1000.0-----------------\n",
            "\n",
            "MSE : 25.622776599053267, \n",
            "PCC : 0.7755286343302475, \n",
            "R²  : 0.5780657955074495\n",
            "\n",
            "-----------The Lasso Regression with alpha = 0.0-----------------\n",
            "\n",
            "MSE : 20.295140049988714, \n",
            "PCC : 0.8227098068087262, \n",
            "R²  : 0.665796806253492\n",
            "\n",
            "-----------The Lasso Regression with alpha = 0.25-----------------\n",
            "\n",
            "MSE : 20.984064082007706, \n",
            "PCC : 0.8155459780766635, \n",
            "R²  : 0.6544521882226548\n",
            "\n",
            "-----------The Lasso Regression with alpha = 0.5-----------------\n",
            "\n",
            "MSE : 21.78576122948502, \n",
            "PCC : 0.8068573346957486, \n",
            "R²  : 0.6412505179486656\n",
            "\n",
            "-----------The Lasso Regression with alpha = 1.0-----------------\n",
            "\n",
            "MSE : 23.00353047878484, \n",
            "PCC : 0.7949368131887922, \n",
            "R²  : 0.6211973243584833\n",
            "\n",
            "-----------The Lasso Regression with alpha = 1000.0-----------------\n",
            "\n",
            "MSE : 64.92444973230221, \n",
            "PCC : 0, \n",
            "R²  : -0.06912090280362837\n",
            "\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "The value of Best alpha for Ridge : 0.0\n",
            "The value of Best alpha for Lasso : 0.0\n",
            "\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "Evaluating Ridge on Test Set:\n",
            "MSE : 10.539190179156172, \n",
            "PCC : 0.8760184188938203, \n",
            "R²  : 0.7297272510883063\n",
            "\n",
            "Evaluating Lasso on Test Set:\n",
            "MSE : 10.539190179156172, \n",
            "PCC: 0.8760184188938203, \n",
            "R²: 0.7297272510883063\n",
            "\n",
            "-------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. 6. (5 point) Apply Scikit-Learn func3on PolynomialFeatures to the feature part of the dataset (columns X1- X5), use the degree 5. Column Y should not be transformed!"
      ],
      "metadata": {
        "id": "cl8JPYWRSSSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying PolynomialFeatures with degree = 5\n",
        "poly_feat = PolynomialFeatures(degree=5, include_bias=False)\n",
        "X_poly = poly_feat.fit_transform(X)\n",
        "X_train_poly, X_temp_poly, Y_train, Y_temp = train_test_split(X_poly, Y, test_size=0.4, random_state=42)\n",
        "X_val_poly, X_test_poly, Y_val, Y_test = train_test_split(X_temp_poly, Y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"--------------------------------------------------------------------------------\\n\")\n",
        "print(f\"Original shape of X : {X.shape}\\n\")\n",
        "print(f\"And Shape of X after Polynomial transformation (i.e. degree=5) : {X_poly.shape}\")\n",
        "print(f\"\\n--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GopVC2v6h-3P",
        "outputId": "b33473c8-8bb5-4e55-d970-7a040cd59eb8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Original shape of X : (205, 5)\n",
            "\n",
            "And Shape of X after Polynomial transformation (i.e. degree=5) : (205, 251)\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. 7. (20 point) Repeat experiments in section 5."
      ],
      "metadata": {
        "id": "qhLW0IezTdtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
        "X_val_poly_scaled = scaler.transform(X_val_poly)\n",
        "X_test_poly_scaled = scaler.transform(X_test_poly)\n",
        "\n",
        "#Creating a Function to find best alpha on validation set\n",
        "def finding_best_alpha(ModelClass, X_train, Y_train, X_val, Y_val, alphas, model_name):\n",
        "    best_alpha = None\n",
        "    best_mse = float('inf')\n",
        "    for alpha in alphas:\n",
        "        if alpha == 0:\n",
        "            model = LinearRegression()\n",
        "        else:\n",
        "            model = ModelClass(alpha=alpha, max_iter=10000)\n",
        "\n",
        "        model.fit(X_train, Y_train)\n",
        "        mse, pcc, r2 = model_evaluation(model, X_val, Y_val, \"Validation\")\n",
        "        print(f\"\\nThe {model_name} with alpha (with Scaled Polynomial Features) = {alpha}\")\n",
        "        print(f\"MSE: {mse}, PCC: {pcc}, R²: {r2}\")\n",
        "\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_alpha = alpha\n",
        "    return best_alpha, best_mse\n",
        "\n",
        "#Finding best alpha for Ridge and Lasso with scaled polynomial features\n",
        "print(\"\\n---------------------- Finding the best alpha for Ridge Regression ------------------------\")\n",
        "best_alpha_ridge_poly, _ = finding_best_alpha(Ridge, X_train_poly_scaled, Y_train, X_val_poly_scaled, Y_val, alphas, \"Ridge Regression\")\n",
        "\n",
        "print(\"\\n----------------------- Finding the best alpha for Lasso Regression ------------------------\")\n",
        "best_alpha_lasso_poly, _ = finding_best_alpha(Lasso, X_train_poly_scaled, Y_train, X_val_poly_scaled, Y_val, alphas, \"Lasso Regression\")\n",
        "\n",
        "print(f\"\\n---------------------------------------------------------------------------------------------\")\n",
        "print(f\"\\nFrom above Best alpha for Ridge Regression (with Scaled Polynomial Features) : {best_alpha_ridge_poly}\")\n",
        "print(f\"From above Best alpha for Lasso Regression (with Scaled Polynomial Features) : {best_alpha_lasso_poly}\")\n",
        "print(f\"\\n---------------------------------------------------------------------------------------------\")\n",
        "\n",
        "#Retraining Ridge with best alpha to evaluate on test set\n",
        "if best_alpha_ridge_poly == 0:\n",
        "    ridge_best_model_poly = LinearRegression()\n",
        "else:\n",
        "    ridge_best_model_poly = Ridge(alpha=best_alpha_ridge_poly, max_iter=10000)  # Increase number of iterations for Ridge\n",
        "\n",
        "ridge_best_model_poly.fit(X_train_poly_scaled, Y_train)\n",
        "print(\"\\nEvaluating Ridge Regression on Test Set (with Scaled Polynomial Features) :\")\n",
        "mse, pcc, r2 = model_evaluation(ridge_best_model_poly, X_test_poly_scaled, Y_test, \"Test\")\n",
        "print(f\"\\nMSE: {mse}, \\nPCC: {pcc}, \\nR²: {r2}\")\n",
        "\n",
        "#Retraining Lasso with best alpha to evaluate on test set\n",
        "if best_alpha_lasso_poly == 0:\n",
        "    lasso_best_model_poly = LinearRegression()\n",
        "else:\n",
        "    lasso_best_model_poly = Lasso(alpha=best_alpha_lasso_poly, max_iter=10000)  # Increase number of iterations for Lasso\n",
        "\n",
        "lasso_best_model_poly.fit(X_train_poly_scaled, Y_train)\n",
        "print(\"\\nEvaluating Lasso Regression on Test Set (with Scaled Polynomial Features) :\")\n",
        "mse, pcc, r2 = model_evaluation(lasso_best_model_poly, X_test_poly_scaled, Y_test, \"Test\")\n",
        "print(f\"\\nMSE: {mse}, \\nPCC: {pcc}, \\nR²: {r2}\")\n",
        "\n",
        "print(f\"\\n---------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxfkgpPhiUq8",
        "outputId": "5af1a145-19c1-4493-bd12-e01dfb3beaf4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------- Finding the best alpha for Ridge Regression ------------------------\n",
            "\n",
            "The Ridge Regression with alpha (with Scaled Polynomial Features) = 0.0\n",
            "MSE: 25075286.604070578, PCC: -0.07593589737610264, R²: -412917.6025101648\n",
            "\n",
            "The Ridge Regression with alpha (with Scaled Polynomial Features) = 0.25\n",
            "MSE: 15.165123478045249, PCC: 0.8763445534499001, R²: 0.7502735784311234\n",
            "\n",
            "The Ridge Regression with alpha (with Scaled Polynomial Features) = 0.5\n",
            "MSE: 16.19549551865446, PCC: 0.8666094330607328, R²: 0.733306283508766\n",
            "\n",
            "The Ridge Regression with alpha (with Scaled Polynomial Features) = 1.0\n",
            "MSE: 17.40496447474242, PCC: 0.855059422323832, R²: 0.713389772123959\n",
            "\n",
            "The Ridge Regression with alpha (with Scaled Polynomial Features) = 1000.0\n",
            "MSE: 30.586546231781046, PCC: 0.7249543527440303, R²: 0.49632663725608883\n",
            "\n",
            "----------------------- Finding the best alpha for Lasso Regression ------------------------\n",
            "\n",
            "The Lasso Regression with alpha (with Scaled Polynomial Features) = 0.0\n",
            "MSE: 25075286.604070578, PCC: -0.07593589737610264, R²: -412917.6025101648\n",
            "\n",
            "The Lasso Regression with alpha (with Scaled Polynomial Features) = 0.25\n",
            "MSE: 23.601377618577576, PCC: 0.7938524454199875, R²: 0.6113524835247262\n",
            "\n",
            "The Lasso Regression with alpha (with Scaled Polynomial Features) = 0.5\n",
            "MSE: 25.041936464567854, PCC: 0.7903379530688674, R²: 0.5876305793681691\n",
            "\n",
            "The Lasso Regression with alpha (with Scaled Polynomial Features) = 1.0\n",
            "MSE: 29.452854124684237, PCC: 0.7770357516464056, R²: 0.5149953196097823\n",
            "\n",
            "The Lasso Regression with alpha (with Scaled Polynomial Features) = 1000.0\n",
            "MSE: 64.92444973230221, PCC: 0, R²: -0.06912090280362837\n",
            "\n",
            "---------------------------------------------------------------------------------------------\n",
            "\n",
            "From above Best alpha for Ridge Regression (with Scaled Polynomial Features) : 0.25\n",
            "From above Best alpha for Lasso Regression (with Scaled Polynomial Features) : 0.25\n",
            "\n",
            "---------------------------------------------------------------------------------------------\n",
            "\n",
            "Evaluating Ridge Regression on Test Set (with Scaled Polynomial Features) :\n",
            "\n",
            "MSE: 5.245327325847402, \n",
            "PCC: 0.9336161098848295, \n",
            "R²: 0.8654859613310529\n",
            "\n",
            "Evaluating Lasso Regression on Test Set (with Scaled Polynomial Features) :\n",
            "\n",
            "MSE: 11.733294461269537, \n",
            "PCC: 0.8749174597342438, \n",
            "R²: 0.6991049887201511\n",
            "\n",
            "---------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. 8. (10 point) Analyze coefficients of Ridge regression and LASSO models. What is the most important feature (a feature having the largest weight)? Which features have weights close to zero?"
      ],
      "metadata": {
        "id": "VkvIslgHjSpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting feature names\n",
        "feature_names = poly_feat.get_feature_names_out(X.columns)\n",
        "\n",
        "#Ridge coefficients (using the best model with polynomial features)\n",
        "ridge_coefficients = ridge_best_model_poly.coef_\n",
        "\n",
        "#LASSO coefficients (using the best model with polynomial features)\n",
        "lasso_coefficients = lasso_best_model_poly.coef_\n",
        "\n",
        "#Creating DataFrame to compare Ridge and LASSO coefficients\n",
        "coeff_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Ridge Coefficient': ridge_coefficients,\n",
        "    'LASSO Coefficient': lasso_coefficients\n",
        "})\n",
        "\n",
        "#First, Sort by absolute value of coefficients to identify the most important features\n",
        "coeff_df['Ridge Coefficient Abs'] = coeff_df['Ridge Coefficient'].abs()\n",
        "coeff_df['LASSO Coefficient Abs'] = coeff_df['LASSO Coefficient'].abs()\n",
        "\n",
        "#Sorting to find the largest coefficients\n",
        "sorted_coefficients_ridge = coeff_df.sort_values(by='Ridge Coefficient Abs', ascending=False)\n",
        "sorted_coefficients_lasso = coeff_df.sort_values(by='LASSO Coefficient Abs', ascending=False)\n",
        "\n",
        "print(\"\\n---------------Sorted Ridge Coefficients : --------------------\\n\")\n",
        "print(sorted_coefficients_ridge)\n",
        "print(\"\\n---------------Sorted LASSO Coefficients : ---------------------\\n\")\n",
        "print(sorted_coefficients_lasso)\n",
        "\n",
        "#Most important feature with the largest weight\n",
        "most_important_feature_ridge = sorted_coefficients_ridge.iloc[0]\n",
        "most_important_feature_lasso = sorted_coefficients_lasso.iloc[0]\n",
        "\n",
        "print(\"\\nMost Important Feature in Ridge Regression:\")\n",
        "print(f\"Feature : {most_important_feature_ridge['Feature']}, Coefficient : {most_important_feature_ridge['Ridge Coefficient']}\")\n",
        "\n",
        "print(\"\\nMost Important Feature in LASSO Regression:\")\n",
        "print(f\"Feature : {most_important_feature_lasso['Feature']}, Coefficient : {most_important_feature_lasso['LASSO Coefficient']}\")\n",
        "\n",
        "#To find features with coefficients close to zero\n",
        "close_to_zero_ridge = sorted_coefficients_ridge[sorted_coefficients_ridge['Ridge Coefficient Abs'] < 1e-2]\n",
        "close_to_zero_lasso = sorted_coefficients_lasso[sorted_coefficients_lasso['LASSO Coefficient Abs'] < 1e-2]\n",
        "\n",
        "print(\"\\nFeatures with coefficients close to zero in Ridge : \")\n",
        "print(close_to_zero_ridge[['Feature', 'Ridge Coefficient']])\n",
        "\n",
        "print(\"\\nFeatures with coefficients close to zero in LASSO : \")\n",
        "print(close_to_zero_lasso[['Feature', 'LASSO Coefficient']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOlozgxmifg-",
        "outputId": "bfe5ef9b-4a3e-4241-b201-c713a23ff8aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------Sorted Ridge Coefficients : --------------------\n",
            "\n",
            "                             Feature  Ridge Coefficient  LASSO Coefficient  \\\n",
            "14                     engine-size^2          -2.892412          -0.000000   \n",
            "39   compression-ratio engine-size^2          -2.783417          -0.000000   \n",
            "2                        engine-size          -2.698602          -1.881565   \n",
            "0                         wheel-base           2.545258           0.000000   \n",
            "243       engine-size length width^3           2.491777          -0.000000   \n",
            "..                               ...                ...                ...   \n",
            "112              engine-size^3 width           0.013664           0.000000   \n",
            "136   wheel-base^3 engine-size width           0.011717           0.000000   \n",
            "20                      wheel-base^3           0.010504           0.000000   \n",
            "66    wheel-base^2 engine-size width           0.005155           0.000000   \n",
            "37        compression-ratio^2 length           0.003134           0.000000   \n",
            "\n",
            "     Ridge Coefficient Abs  LASSO Coefficient Abs  \n",
            "14                2.892412               0.000000  \n",
            "39                2.783417               0.000000  \n",
            "2                 2.698602               1.881565  \n",
            "0                 2.545258               0.000000  \n",
            "243               2.491777               0.000000  \n",
            "..                     ...                    ...  \n",
            "112               0.013664               0.000000  \n",
            "136               0.011717               0.000000  \n",
            "20                0.010504               0.000000  \n",
            "66                0.005155               0.000000  \n",
            "37                0.003134               0.000000  \n",
            "\n",
            "[251 rows x 5 columns]\n",
            "\n",
            "---------------Sorted LASSO Coefficients : ---------------------\n",
            "\n",
            "                             Feature  Ridge Coefficient  LASSO Coefficient  \\\n",
            "3                             length          -1.945057          -2.361097   \n",
            "1                  compression-ratio           2.384797           2.318401   \n",
            "2                        engine-size          -2.698602          -1.881565   \n",
            "4                              width          -1.185653          -0.630254   \n",
            "0                         wheel-base           2.545258           0.000000   \n",
            "..                               ...                ...                ...   \n",
            "90               compression-ratio^4          -1.235212           0.000000   \n",
            "91   compression-ratio^3 engine-size          -0.075082           0.000000   \n",
            "92        compression-ratio^3 length          -0.325158           0.000000   \n",
            "93         compression-ratio^3 width          -0.649298           0.000000   \n",
            "250                          width^5          -0.962346          -0.000000   \n",
            "\n",
            "     Ridge Coefficient Abs  LASSO Coefficient Abs  \n",
            "3                 1.945057               2.361097  \n",
            "1                 2.384797               2.318401  \n",
            "2                 2.698602               1.881565  \n",
            "4                 1.185653               0.630254  \n",
            "0                 2.545258               0.000000  \n",
            "..                     ...                    ...  \n",
            "90                1.235212               0.000000  \n",
            "91                0.075082               0.000000  \n",
            "92                0.325158               0.000000  \n",
            "93                0.649298               0.000000  \n",
            "250               0.962346               0.000000  \n",
            "\n",
            "[251 rows x 5 columns]\n",
            "\n",
            "Most Important Feature in Ridge Regression:\n",
            "Feature : engine-size^2, Coefficient : -2.892411621915059\n",
            "\n",
            "Most Important Feature in LASSO Regression:\n",
            "Feature : length, Coefficient : -2.3610974449881055\n",
            "\n",
            "Features with coefficients close to zero in Ridge : \n",
            "                           Feature  Ridge Coefficient\n",
            "66  wheel-base^2 engine-size width           0.005155\n",
            "37      compression-ratio^2 length           0.003134\n",
            "\n",
            "Features with coefficients close to zero in LASSO : \n",
            "                                               Feature  LASSO Coefficient\n",
            "0                                           wheel-base                0.0\n",
            "167            wheel-base compression-ratio^2 length^2                0.0\n",
            "172   wheel-base compression-ratio engine-size^2 width                0.0\n",
            "171  wheel-base compression-ratio engine-size^2 length                0.0\n",
            "170         wheel-base compression-ratio engine-size^3                0.0\n",
            "..                                                 ...                ...\n",
            "90                                 compression-ratio^4                0.0\n",
            "91                     compression-ratio^3 engine-size                0.0\n",
            "92                          compression-ratio^3 length                0.0\n",
            "93                           compression-ratio^3 width                0.0\n",
            "250                                            width^5               -0.0\n",
            "\n",
            "[247 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9GPa3dvQcEEr"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}